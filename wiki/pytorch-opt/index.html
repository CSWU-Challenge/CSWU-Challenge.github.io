<!doctype html><html lang=zh class=no-js> <head><meta charset=utf-8><meta name=viewport content="width=device-width,initial-scale=1"><meta name=description content="Southeast University HPC platform."><meta name=author content=CSWU-Challenge><link href=https://CSWU-Challenge.github.io/wiki/pytorch-opt/ rel=canonical><link rel=icon href=../../assets/favicon.png><meta name=generator content="mkdocs-1.6.1, mkdocs-material-8.2.5"><title>PyTorch模型优化思路 - 东南大学超算平台</title><link rel=stylesheet href=../../assets/stylesheets/main.2d9f7617.min.css><link rel=stylesheet href=../../assets/stylesheets/palette.e6a45f82.min.css><link rel=preconnect href=https://fonts.gstatic.com crossorigin><link rel=stylesheet href="https://fonts.googleapis.com/css?family=Roboto:300,300i,400,400i,700,700i%7CRoboto+Mono:400,400i,700,700i&display=fallback"><style>:root{--md-text-font:"Roboto";--md-code-font:"Roboto Mono"}</style><script>__md_scope=new URL("../..",location),__md_get=(e,_=localStorage,t=__md_scope)=>JSON.parse(_.getItem(t.pathname+"."+e)),__md_set=(e,_,t=localStorage,a=__md_scope)=>{try{t.setItem(a.pathname+"."+e,JSON.stringify(_))}catch(e){}}</script><!-- Global site tag (gtag.js) - Google Analytics --><script async src="https://www.googletagmanager.com/gtag/js?id=G-7Y7KMG2XPN"></script><script>
  window.dataLayer = window.dataLayer || [];
  function gtag(){dataLayer.push(arguments);}
  gtag('js', new Date());

  gtag('config', 'G-7Y7KMG2XPN');
</script><link rel=stylesheet href=../../overrides/assets/stylesheets/main.d9227bb8.min.css></head> <body dir=ltr data-md-color-scheme=default data-md-color-primary=teal data-md-color-accent=teal> <script>var palette=__md_get("__palette");if(palette&&"object"==typeof palette.color)for(var key of Object.keys(palette.color))document.body.setAttribute("data-md-color-"+key,palette.color[key])</script> <input class=md-toggle data-md-toggle=drawer type=checkbox id=__drawer autocomplete=off> <input class=md-toggle data-md-toggle=search type=checkbox id=__search autocomplete=off> <label class=md-overlay for=__drawer></label> <div data-md-component=skip> <a href=#pytorch class=md-skip> 跳转至 </a> </div> <header class=md-header data-md-component=header> <nav class="md-header__inner md-grid" aria-label=页眉> <a href=../.. title=东南大学超算平台 class="md-header__button md-logo" aria-label=东南大学超算平台 data-md-component=logo> <svg xmlns=http://www.w3.org/2000/svg viewbox="0 0 89 89"> <path d=M3.136,17.387l0,42.932l42.932,21.467l-42.932,-64.399Z /> <path d=M21.91,8l42.933,64.398l-18.775,9.388l-42.932,-64.399l18.774,-9.387Z style="fill-opacity: 0.5"/> <path d=M67.535,17.387l-27.262,18.156l21.878,32.818l5.384,2.691l0,-53.665Z /> <path d=M67.535,17.387l0,53.666l18.774,-9.388l0,-53.665l-18.774,9.387Z style="fill-opacity: 0.25"/> </svg> </a> <label class="md-header__button md-icon" for=__drawer> <svg xmlns=http://www.w3.org/2000/svg viewbox="0 0 24 24"><path d="M3 6h18v2H3V6m0 5h18v2H3v-2m0 5h18v2H3v-2z"/></svg> </label> <div class=md-header__title data-md-component=header-title> <div class=md-header__ellipsis> <div class=md-header__topic> <span class=md-ellipsis> 东南大学超算平台 </span> </div> <div class=md-header__topic data-md-component=header-topic> <span class=md-ellipsis> PyTorch模型优化思路 </span> </div> </div> </div> <form class=md-header__option data-md-component=palette> <input class=md-option data-md-color-media data-md-color-scheme=default data-md-color-primary=teal data-md-color-accent=teal aria-label="Switch to dark mode" type=radio name=__palette id=__palette_1> <label class="md-header__button md-icon" title="Switch to dark mode" for=__palette_2 hidden> <svg xmlns=http://www.w3.org/2000/svg viewbox="0 0 24 24"><path d="M12 7a5 5 0 0 1 5 5 5 5 0 0 1-5 5 5 5 0 0 1-5-5 5 5 0 0 1 5-5m0 2a3 3 0 0 0-3 3 3 3 0 0 0 3 3 3 3 0 0 0 3-3 3 3 0 0 0-3-3m0-7 2.39 3.42C13.65 5.15 12.84 5 12 5c-.84 0-1.65.15-2.39.42L12 2M3.34 7l4.16-.35A7.2 7.2 0 0 0 5.94 8.5c-.44.74-.69 1.5-.83 2.29L3.34 7m.02 10 1.76-3.77a7.131 7.131 0 0 0 2.38 4.14L3.36 17M20.65 7l-1.77 3.79a7.023 7.023 0 0 0-2.38-4.15l4.15.36m-.01 10-4.14.36c.59-.51 1.12-1.14 1.54-1.86.42-.73.69-1.5.83-2.29L20.64 17M12 22l-2.41-3.44c.74.27 1.55.44 2.41.44.82 0 1.63-.17 2.37-.44L12 22z"/></svg> </label> <input class=md-option data-md-color-media data-md-color-scheme=slate data-md-color-primary=black data-md-color-accent=black aria-label="Switch to light mode" type=radio name=__palette id=__palette_2> <label class="md-header__button md-icon" title="Switch to light mode" for=__palette_1 hidden> <svg xmlns=http://www.w3.org/2000/svg viewbox="0 0 24 24"><path d="m17.75 4.09-2.53 1.94.91 3.06-2.63-1.81-2.63 1.81.91-3.06-2.53-1.94L12.44 4l1.06-3 1.06 3 3.19.09m3.5 6.91-1.64 1.25.59 1.98-1.7-1.17-1.7 1.17.59-1.98L15.75 11l2.06-.05L18.5 9l.69 1.95 2.06.05m-2.28 4.95c.83-.08 1.72 1.1 1.19 1.85-.32.45-.66.87-1.08 1.27C15.17 23 8.84 23 4.94 19.07c-3.91-3.9-3.91-10.24 0-14.14.4-.4.82-.76 1.27-1.08.75-.53 1.93.36 1.85 1.19-.27 2.86.69 5.83 2.89 8.02a9.96 9.96 0 0 0 8.02 2.89m-1.64 2.02a12.08 12.08 0 0 1-7.8-3.47c-2.17-2.19-3.33-5-3.49-7.82-2.81 3.14-2.7 7.96.31 10.98 3.02 3.01 7.84 3.12 10.98.31z"/></svg> </label> </form> <div class=md-header__source> <a href=https://github.com/CSWU-Challenge/CSWU-Challenge.github.io title=前往仓库 class=md-source data-md-component=source> <div class="md-source__icon md-icon"> <svg xmlns=http://www.w3.org/2000/svg viewbox="0 0 496 512"><!-- Font Awesome Free 6.0.0 by @fontawesome - https://fontawesome.com License - https://fontawesome.com/license/free (Icons: CC BY 4.0, Fonts: SIL OFL 1.1, Code: MIT License) Copyright 2022 Fonticons, Inc.--><path d="M165.9 397.4c0 2-2.3 3.6-5.2 3.6-3.3.3-5.6-1.3-5.6-3.6 0-2 2.3-3.6 5.2-3.6 3-.3 5.6 1.3 5.6 3.6zm-31.1-4.5c-.7 2 1.3 4.3 4.3 4.9 2.6 1 5.6 0 6.2-2s-1.3-4.3-4.3-5.2c-2.6-.7-5.5.3-6.2 2.3zm44.2-1.7c-2.9.7-4.9 2.6-4.6 4.9.3 2 2.9 3.3 5.9 2.6 2.9-.7 4.9-2.6 4.6-4.6-.3-1.9-3-3.2-5.9-2.9zM244.8 8C106.1 8 0 113.3 0 252c0 110.9 69.8 205.8 169.5 239.2 12.8 2.3 17.3-5.6 17.3-12.1 0-6.2-.3-40.4-.3-61.4 0 0-70 15-84.7-29.8 0 0-11.4-29.1-27.8-36.6 0 0-22.9-15.7 1.6-15.4 0 0 24.9 2 38.6 25.8 21.9 38.6 58.6 27.5 72.9 20.9 2.3-16 8.8-27.1 16-33.7-55.9-6.2-112.3-14.3-112.3-110.5 0-27.5 7.6-41.3 23.6-58.9-2.6-6.5-11.1-33.3 2.6-67.9 20.9-6.5 69 27 69 27 20-5.6 41.5-8.5 62.8-8.5s42.8 2.9 62.8 8.5c0 0 48.1-33.6 69-27 13.7 34.7 5.2 61.4 2.6 67.9 16 17.7 25.8 31.5 25.8 58.9 0 96.5-58.9 104.2-114.8 110.5 9.2 7.9 17 22.9 17 46.4 0 33.7-.3 75.4-.3 83.6 0 6.5 4.6 14.4 17.3 12.1C428.2 457.8 496 362.9 496 252 496 113.3 383.5 8 244.8 8zM97.2 352.9c-1.3 1-1 3.3.7 5.2 1.6 1.6 3.9 2.3 5.2 1 1.3-1 1-3.3-.7-5.2-1.6-1.6-3.9-2.3-5.2-1zm-10.8-8.1c-.7 1.3.3 2.9 2.3 3.9 1.6 1 3.6.7 4.3-.7.7-1.3-.3-2.9-2.3-3.9-2-.6-3.6-.3-4.3.7zm32.4 35.6c-1.6 1.3-1 4.3 1.3 6.2 2.3 2.3 5.2 2.6 6.5 1 1.3-1.3.7-4.3-1.3-6.2-2.2-2.3-5.2-2.6-6.5-1zm-11.4-14.7c-1.6 1-1.6 3.6 0 5.9 1.6 2.3 4.3 3.3 5.6 2.3 1.6-1.3 1.6-3.9 0-6.2-1.4-2.3-4-3.3-5.6-2z"/></svg> </div> <div class=md-source__repository> CSWU-Challeng </div> </a> </div> </nav> </header> <div class=md-container data-md-component=container> <nav class=md-tabs aria-label=标签 data-md-component=tabs> <div class="md-tabs__inner md-grid"> <ul class=md-tabs__list> <li class=md-tabs__item> <a href=../.. class=md-tabs__link> Home </a> </li> <li class=md-tabs__item> <a href=../ASC-introduction/ class="md-tabs__link md-tabs__link--active"> Wiki </a> </li> <li class=md-tabs__item> <a href=../../page/high-light/ class=md-tabs__link> High Light </a> </li> <li class=md-tabs__item> <a href=../../page/contributor/ class=md-tabs__link> Contirbutor </a> </li> <li class=md-tabs__item> <a href=../../page/to-contributors/ class=md-tabs__link> How-To </a> </li> <li class=md-tabs__item> <a href=../../page/Download/ class=md-tabs__link> Download </a> </li> </ul> </div> </nav> <main class=md-main data-md-component=main> <div class="md-main__inner md-grid"> <div class="md-sidebar md-sidebar--primary" data-md-component=sidebar data-md-type=navigation> <div class=md-sidebar__scrollwrap> <div class=md-sidebar__inner> <nav class="md-nav md-nav--primary md-nav--lifted" aria-label=导航栏 data-md-level=0> <label class=md-nav__title for=__drawer> <a href=../.. title=东南大学超算平台 class="md-nav__button md-logo" aria-label=东南大学超算平台 data-md-component=logo> <svg xmlns=http://www.w3.org/2000/svg viewbox="0 0 89 89"> <path d=M3.136,17.387l0,42.932l42.932,21.467l-42.932,-64.399Z /> <path d=M21.91,8l42.933,64.398l-18.775,9.388l-42.932,-64.399l18.774,-9.387Z style="fill-opacity: 0.5"/> <path d=M67.535,17.387l-27.262,18.156l21.878,32.818l5.384,2.691l0,-53.665Z /> <path d=M67.535,17.387l0,53.666l18.774,-9.388l0,-53.665l-18.774,9.387Z style="fill-opacity: 0.25"/> </svg> </a> 东南大学超算平台 </label> <div class=md-nav__source> <a href=https://github.com/CSWU-Challenge/CSWU-Challenge.github.io title=前往仓库 class=md-source data-md-component=source> <div class="md-source__icon md-icon"> <svg xmlns=http://www.w3.org/2000/svg viewbox="0 0 496 512"><!-- Font Awesome Free 6.0.0 by @fontawesome - https://fontawesome.com License - https://fontawesome.com/license/free (Icons: CC BY 4.0, Fonts: SIL OFL 1.1, Code: MIT License) Copyright 2022 Fonticons, Inc.--><path d="M165.9 397.4c0 2-2.3 3.6-5.2 3.6-3.3.3-5.6-1.3-5.6-3.6 0-2 2.3-3.6 5.2-3.6 3-.3 5.6 1.3 5.6 3.6zm-31.1-4.5c-.7 2 1.3 4.3 4.3 4.9 2.6 1 5.6 0 6.2-2s-1.3-4.3-4.3-5.2c-2.6-.7-5.5.3-6.2 2.3zm44.2-1.7c-2.9.7-4.9 2.6-4.6 4.9.3 2 2.9 3.3 5.9 2.6 2.9-.7 4.9-2.6 4.6-4.6-.3-1.9-3-3.2-5.9-2.9zM244.8 8C106.1 8 0 113.3 0 252c0 110.9 69.8 205.8 169.5 239.2 12.8 2.3 17.3-5.6 17.3-12.1 0-6.2-.3-40.4-.3-61.4 0 0-70 15-84.7-29.8 0 0-11.4-29.1-27.8-36.6 0 0-22.9-15.7 1.6-15.4 0 0 24.9 2 38.6 25.8 21.9 38.6 58.6 27.5 72.9 20.9 2.3-16 8.8-27.1 16-33.7-55.9-6.2-112.3-14.3-112.3-110.5 0-27.5 7.6-41.3 23.6-58.9-2.6-6.5-11.1-33.3 2.6-67.9 20.9-6.5 69 27 69 27 20-5.6 41.5-8.5 62.8-8.5s42.8 2.9 62.8 8.5c0 0 48.1-33.6 69-27 13.7 34.7 5.2 61.4 2.6 67.9 16 17.7 25.8 31.5 25.8 58.9 0 96.5-58.9 104.2-114.8 110.5 9.2 7.9 17 22.9 17 46.4 0 33.7-.3 75.4-.3 83.6 0 6.5 4.6 14.4 17.3 12.1C428.2 457.8 496 362.9 496 252 496 113.3 383.5 8 244.8 8zM97.2 352.9c-1.3 1-1 3.3.7 5.2 1.6 1.6 3.9 2.3 5.2 1 1.3-1 1-3.3-.7-5.2-1.6-1.6-3.9-2.3-5.2-1zm-10.8-8.1c-.7 1.3.3 2.9 2.3 3.9 1.6 1 3.6.7 4.3-.7.7-1.3-.3-2.9-2.3-3.9-2-.6-3.6-.3-4.3.7zm32.4 35.6c-1.6 1.3-1 4.3 1.3 6.2 2.3 2.3 5.2 2.6 6.5 1 1.3-1.3.7-4.3-1.3-6.2-2.2-2.3-5.2-2.6-6.5-1zm-11.4-14.7c-1.6 1-1.6 3.6 0 5.9 1.6 2.3 4.3 3.3 5.6 2.3 1.6-1.3 1.6-3.9 0-6.2-1.4-2.3-4-3.3-5.6-2z"/></svg> </div> <div class=md-source__repository> CSWU-Challeng </div> </a> </div> <ul class=md-nav__list data-md-scrollfix> <li class=md-nav__item> <a href=../.. class=md-nav__link> Home </a> </li> <li class="md-nav__item md-nav__item--active md-nav__item--nested"> <input class="md-nav__toggle md-toggle" data-md-toggle=__nav_2 type=checkbox id=__nav_2 checked> <label class=md-nav__link for=__nav_2> Wiki <span class="md-nav__icon md-icon"></span> </label> <nav class=md-nav aria-label=Wiki data-md-level=1> <label class=md-nav__title for=__nav_2> <span class="md-nav__icon md-icon"></span> Wiki </label> <ul class=md-nav__list data-md-scrollfix> <li class=md-nav__item> <a href=../ASC-introduction/ class=md-nav__link> 超算竞赛快速入门 </a> </li> <li class=md-nav__item> <a href=../Linux-base/ class=md-nav__link> Linux基础教程 </a> </li> <li class=md-nav__item> <a href=../conda%26pip_base/ class=md-nav__link> conda与pip基础 </a> </li> <li class=md-nav__item> <a href=../Proposal-writing/ class=md-nav__link> 如何写Proposal </a> </li> <li class=md-nav__item> <a href=../vimtutor/ class=md-nav__link> VIM指令入门 </a> </li> <li class="md-nav__item md-nav__item--active"> <input class="md-nav__toggle md-toggle" data-md-toggle=toc type=checkbox id=__toc> <label class="md-nav__link md-nav__link--active" for=__toc> PyTorch模型优化思路 <span class="md-nav__icon md-icon"></span> </label> <a href=./ class="md-nav__link md-nav__link--active"> PyTorch模型优化思路 </a> <nav class="md-nav md-nav--secondary" aria-label=目录> <label class=md-nav__title for=__toc> <span class="md-nav__icon md-icon"></span> 目录 </label> <ul class=md-nav__list data-md-component=toc data-md-scrollfix> <li class=md-nav__item> <a href=#_1 class=md-nav__link> 前言 </a> </li> <li class=md-nav__item> <a href=#_2 class=md-nav__link> 考虑换一种学习率 </a> </li> <li class=md-nav__item> <a href=#dataloader class=md-nav__link> 在DataLoader里使用多个线程和固定内存 </a> </li> <li class=md-nav__item> <a href=#batch-size class=md-nav__link> 增大batch size </a> </li> <li class=md-nav__item> <a href=#amp class=md-nav__link> 使用混合精度(AMP) </a> </li> <li class=md-nav__item> <a href=#_3 class=md-nav__link> 考虑使用另一种优化器 </a> </li> <li class=md-nav__item> <a href=#cudnn class=md-nav__link> 开启cudNN基准测试 </a> </li> <li class=md-nav__item> <a href=#cpugpu class=md-nav__link> 小心CPU和GPU之间频繁的数据转换 </a> </li> <li class=md-nav__item> <a href=#_4 class=md-nav__link> 使用梯度累积 </a> </li> <li class=md-nav__item> <a href=#distributed-data-parallel class=md-nav__link> 使用Distributed Data Parallel 来进行多卡训练 </a> </li> <li class=md-nav__item> <a href=#none0 class=md-nav__link> 将梯度设置为None而不是0 </a> </li> <li class=md-nav__item> <a href=#as_tensortensor class=md-nav__link> 使用.as_tensor()而不是.tensor() </a> </li> <li class=md-nav__item> <a href=#gradient-clipping class=md-nav__link> 使用梯度剪裁(gradient clipping) </a> </li> <li class=md-nav__item> <a href=#batchnormbias class=md-nav__link> 在BatchNorm之前关掉bias </a> </li> <li class=md-nav__item> <a href=#validation class=md-nav__link> 在做validation的时候关掉梯度计算 </a> </li> <li class=md-nav__item> <a href=#_5 class=md-nav__link> 预加载数据 </a> </li> </ul> </nav> </li> <li class=md-nav__item> <a href=../tensorflow-opt/ class=md-nav__link> TensorFlow模型优化思路 </a> </li> <li class=md-nav__item> <a href=../latex-manual/ class=md-nav__link> Latex环境配置及编译优化 </a> </li> <li class=md-nav__item> <a href=../parallel_coding/ class=md-nav__link> c++并行编程入门 </a> </li> <li class=md-nav__item> <a href=../how-gui-work/ class=md-nav__link> 从内存到屏幕：GUI 显示手段的进化史 </a> </li> <li class=md-nav__item> <a href=../cuda-project/ class=md-nav__link> cuda编程(待完善) </a> </li> </ul> </nav> </li> <li class=md-nav__item> <a href=../../page/high-light/ class=md-nav__link> High Light </a> </li> <li class=md-nav__item> <a href=../../page/contributor/ class=md-nav__link> Contirbutor </a> </li> <li class=md-nav__item> <a href=../../page/to-contributors/ class=md-nav__link> How-To </a> </li> <li class=md-nav__item> <a href=../../page/Download/ class=md-nav__link> Download </a> </li> </ul> </nav> </div> </div> </div> <div class="md-sidebar md-sidebar--secondary" data-md-component=sidebar data-md-type=toc> <div class=md-sidebar__scrollwrap> <div class=md-sidebar__inner> <nav class="md-nav md-nav--secondary" aria-label=目录> <label class=md-nav__title for=__toc> <span class="md-nav__icon md-icon"></span> 目录 </label> <ul class=md-nav__list data-md-component=toc data-md-scrollfix> <li class=md-nav__item> <a href=#_1 class=md-nav__link> 前言 </a> </li> <li class=md-nav__item> <a href=#_2 class=md-nav__link> 考虑换一种学习率 </a> </li> <li class=md-nav__item> <a href=#dataloader class=md-nav__link> 在DataLoader里使用多个线程和固定内存 </a> </li> <li class=md-nav__item> <a href=#batch-size class=md-nav__link> 增大batch size </a> </li> <li class=md-nav__item> <a href=#amp class=md-nav__link> 使用混合精度(AMP) </a> </li> <li class=md-nav__item> <a href=#_3 class=md-nav__link> 考虑使用另一种优化器 </a> </li> <li class=md-nav__item> <a href=#cudnn class=md-nav__link> 开启cudNN基准测试 </a> </li> <li class=md-nav__item> <a href=#cpugpu class=md-nav__link> 小心CPU和GPU之间频繁的数据转换 </a> </li> <li class=md-nav__item> <a href=#_4 class=md-nav__link> 使用梯度累积 </a> </li> <li class=md-nav__item> <a href=#distributed-data-parallel class=md-nav__link> 使用Distributed Data Parallel 来进行多卡训练 </a> </li> <li class=md-nav__item> <a href=#none0 class=md-nav__link> 将梯度设置为None而不是0 </a> </li> <li class=md-nav__item> <a href=#as_tensortensor class=md-nav__link> 使用.as_tensor()而不是.tensor() </a> </li> <li class=md-nav__item> <a href=#gradient-clipping class=md-nav__link> 使用梯度剪裁(gradient clipping) </a> </li> <li class=md-nav__item> <a href=#batchnormbias class=md-nav__link> 在BatchNorm之前关掉bias </a> </li> <li class=md-nav__item> <a href=#validation class=md-nav__link> 在做validation的时候关掉梯度计算 </a> </li> <li class=md-nav__item> <a href=#_5 class=md-nav__link> 预加载数据 </a> </li> </ul> </nav> </div> </div> </div> <div class=md-content data-md-component=content> <article class="md-content__inner md-typeset"> <h1 id=pytorch>PyTorch模型优化思路<a class=headerlink href=#pytorch title="Permanent link">&para;</a></h1> <h2 id=_1>前言<a class=headerlink href=#_1 title="Permanent link">&para;</a></h2> <p>&emsp;&emsp;近年来AI模型成为ASC竞赛选题的香饽饽，如2022年的三四两题分别是基于pytorch的大型语言模型，和基于tensorflow的分子动力学模型。AI模型的优化可以从许多方面入手，本文参考Lorenze Kuhn的文章<a href=https://www.reddit.com/r/MachineLearning/comments/kvs1ex/d_here_are_17_ways_of_making_pytorch_training/ >Here are 17 ways of making PyTorch training faster – what did I miss?</a>，对其进行翻译和总结，介绍pytorch框架的通用优化思路。</p> <p>&emsp;&emsp;<strong>注意：本文所讲方法仅供参考，帮助大家打开思路。你可能会发现这些方法并不会有太大效果，甚至没有效果。如果想有所突破，必须靠自己深度阅读代码，对症下药。</strong></p> <h2 id=_2>考虑换一种学习率<a class=headerlink href=#_2 title="Permanent link">&para;</a></h2> <p>&emsp;&emsp;学习率对模型收敛速度和泛化能力有很大影响。Cyclical Learning Rates 和oneCycle learning rate 是 Leslie N. Smith提出的两种自适应学习率方法。（参见<a href=https://arxiv.org/pdf/1506.01186.pdf>这里</a>和<a href=https://arxiv.org/abs/1708.07120>这里</a>）oneCycle learning rate schedule看起来像这样：</p> <p><img alt=1cycle src=https://img.zsaqwq.com/images/2022/03/16/image.png></p> <p>&emsp;&emsp;PyTorch实现了这两种方法:<code>torch.optim.lr_scheduler.CyclicLR</code> 和<code>torch.optim.lr_scheduler.OneCycleLR</code>。具体用法请见<a href=https://pytorch.org/docs/stable/optim.html>官方文档</a>。</p> <p>&emsp;&emsp;注意这两种方法需要给定超参数。关于超参数的选择请看<a href=https://towardsdatascience.com/hyper-parameter-tuning-techniques-in-deep-learning-4dad592c63c8>这条帖子</a>和<a href=https://github.com/davidtvs/pytorch-lr-finder>这个仓库</a></p> <h2 id=dataloader>在DataLoader里使用多个线程和固定内存<a class=headerlink href=#dataloader title="Permanent link">&para;</a></h2> <p>&emsp;&emsp;使用<code>torch.utils.data.DataLoader</code>时，设置<code>num_workers&gt;0</code>，而不是使用它的默认值0.并且设置<code>pin_memory=True</code>，而不是默认的False。具体的解释参见<a href=https://pytorch.org/docs/stable/data.html>这里</a>。</p> <p>&emsp;&emsp;经验表明，当num_workers等于GPU数量的四倍时效果最好。注意这种方法会增大CPU负荷。</p> <h2 id=batch-size>增大batch size<a class=headerlink href=#batch-size title="Permanent link">&para;</a></h2> <p>&emsp;&emsp;使用你的GPU所允许的最大的batch size可以提高你的训练速度。调整batch size时需要等比例的调整learning rate。</p> <p>&emsp;&emsp;OpenAI对此有一篇很漂亮的<a href=https://arxiv.org/pdf/1812.06162.pdf>论文</a>可供参考。使用大batch size的缺点是，这可能会降低模型的泛化能力。</p> <h2 id=amp>使用混合精度(AMP)<a class=headerlink href=#amp title="Permanent link">&para;</a></h2> <p>&emsp;&emsp;Pytorch 1.6增加了混合精度训练的官方实现。使用FP16和FP32混合精度可以训练地更快，而且相比单精度(FP32)训练并没有精度损失。下面是一个使用AMP的例子：</p> <div class=highlight><pre><span></span><code><a id=__codelineno-0-1 name=__codelineno-0-1 href=#__codelineno-0-1></a>import torch
<a id=__codelineno-0-2 name=__codelineno-0-2 href=#__codelineno-0-2></a># Creates once at the beginning of training
<a id=__codelineno-0-3 name=__codelineno-0-3 href=#__codelineno-0-3></a>scaler = torch.cuda.amp.GradScaler()
<a id=__codelineno-0-4 name=__codelineno-0-4 href=#__codelineno-0-4></a>
<a id=__codelineno-0-5 name=__codelineno-0-5 href=#__codelineno-0-5></a>for data, label in data_iter:
<a id=__codelineno-0-6 name=__codelineno-0-6 href=#__codelineno-0-6></a>   optimizer.zero_grad()
<a id=__codelineno-0-7 name=__codelineno-0-7 href=#__codelineno-0-7></a>   # Casts operations to mixed precision
<a id=__codelineno-0-8 name=__codelineno-0-8 href=#__codelineno-0-8></a>   with torch.cuda.amp.autocast():
<a id=__codelineno-0-9 name=__codelineno-0-9 href=#__codelineno-0-9></a>      loss = model(data)
<a id=__codelineno-0-10 name=__codelineno-0-10 href=#__codelineno-0-10></a>
<a id=__codelineno-0-11 name=__codelineno-0-11 href=#__codelineno-0-11></a>   # Scales the loss, and calls backward()
<a id=__codelineno-0-12 name=__codelineno-0-12 href=#__codelineno-0-12></a>   # to create scaled gradients
<a id=__codelineno-0-13 name=__codelineno-0-13 href=#__codelineno-0-13></a>   scaler.scale(loss).backward()
<a id=__codelineno-0-14 name=__codelineno-0-14 href=#__codelineno-0-14></a>
<a id=__codelineno-0-15 name=__codelineno-0-15 href=#__codelineno-0-15></a>   # Unscales gradients and calls
<a id=__codelineno-0-16 name=__codelineno-0-16 href=#__codelineno-0-16></a>   # or skips optimizer.step()
<a id=__codelineno-0-17 name=__codelineno-0-17 href=#__codelineno-0-17></a>   scaler.step(optimizer)
<a id=__codelineno-0-18 name=__codelineno-0-18 href=#__codelineno-0-18></a>
<a id=__codelineno-0-19 name=__codelineno-0-19 href=#__codelineno-0-19></a>   # Updates the scale for next iteration
<a id=__codelineno-0-20 name=__codelineno-0-20 href=#__codelineno-0-20></a>   scaler.update()
</code></pre></div> <p>AMP训练的benchmark可以参考这篇<a href=https://pytorch.org/blog/accelerating-training-on-nvidia-gpus-with-pytorch-automatic-mixed-precision/ >文章</a></p> <h2 id=_3>考虑使用另一种优化器<a class=headerlink href=#_3 title="Permanent link">&para;</a></h2> <p>&emsp;&emsp;AdamW往往比Adam有更好的优化效率。相关文章参见<a href=https://www.fast.ai/2018/07/02/adam-weight-decay/ >这篇</a>。</p> <p>&emsp;&emsp;此外还可以尝试最近异军突起的LAMB优化器。</p> <p>&emsp;&emsp;如果使用英伟达的显卡，可以安装英伟达的APEX包，里面提供了针对NVIDA GPU而改良的常见优化器，比如Adam。</p> <h2 id=cudnn>开启cudNN基准测试<a class=headerlink href=#cudnn title="Permanent link">&para;</a></h2> <p>&emsp;&emsp;如果你的模型架构是固定的，并且输入数据的size是常数，那么可以尝试设置<code>torch.backends.cudnn.benchmark = True</code>。这会启动cudNN autotuner来测试卷积计算的不同方法，并最终选用最佳方法。 &emsp;&emsp;需要注意的是，如果你把batch size最大化了，那么这个测试将会非常慢。</p> <h2 id=cpugpu>小心CPU和GPU之间频繁的数据转换<a class=headerlink href=#cpugpu title="Permanent link">&para;</a></h2> <p>&emsp;&emsp;注意你的代码中是否频繁调用了<code>tensor.cpu()</code>或者<code>tensor.cuda()</code>，这会非常耗时。</p> <p>&emsp;&emsp;如果你在创建一个新的tensor，你可以通过设置参数<code>device=torch.device('cuda:0')</code>来把数据直接创建在GPU上。</p> <h2 id=_4>使用梯度累积<a class=headerlink href=#_4 title="Permanent link">&para;</a></h2> <p>&emsp;&emsp;这种方法变相增加了batch size。如果你的GPU memory不足以容纳较大的batch，你可以把一个batch分几次输入，从而算出总梯度。你可以在调用<code>optimizaer.step</code>之前多次调用<code>.backward</code>，来实现这个方法。下面是一个例子。</p> <div class=highlight><pre><span></span><code><a id=__codelineno-1-1 name=__codelineno-1-1 href=#__codelineno-1-1></a>model.zero_grad()                                   # Reset gradients tensors
<a id=__codelineno-1-2 name=__codelineno-1-2 href=#__codelineno-1-2></a>for i, (inputs, labels) in enumerate(training_set):
<a id=__codelineno-1-3 name=__codelineno-1-3 href=#__codelineno-1-3></a>    predictions = model(inputs)                     # Forward pass
<a id=__codelineno-1-4 name=__codelineno-1-4 href=#__codelineno-1-4></a>    loss = loss_function(predictions, labels)       # Compute loss function
<a id=__codelineno-1-5 name=__codelineno-1-5 href=#__codelineno-1-5></a>    loss = loss / accumulation_steps                # Normalize our loss (if averaged)
<a id=__codelineno-1-6 name=__codelineno-1-6 href=#__codelineno-1-6></a>    loss.backward()                                 # Backward pass
<a id=__codelineno-1-7 name=__codelineno-1-7 href=#__codelineno-1-7></a>    if (i+1) % accumulation_steps == 0:             # Wait for several backward steps
<a id=__codelineno-1-8 name=__codelineno-1-8 href=#__codelineno-1-8></a>        optimizer.step()                            # Now we can do an optimizer step
<a id=__codelineno-1-9 name=__codelineno-1-9 href=#__codelineno-1-9></a>        model.zero_grad()                           # Reset gradients tensors
<a id=__codelineno-1-10 name=__codelineno-1-10 href=#__codelineno-1-10></a>        if (i+1) % evaluation_steps == 0:           # Evaluate the model when we...
<a id=__codelineno-1-11 name=__codelineno-1-11 href=#__codelineno-1-11></a>            evaluate_model()                        # ...have no gradients accumulated
</code></pre></div> <h2 id=distributed-data-parallel>使用Distributed Data Parallel 来进行多卡训练<a class=headerlink href=#distributed-data-parallel title="Permanent link">&para;</a></h2> <p>&emsp;&emsp;使用<code>torch.nn.DistributedDataParallel</code>而不是<code>torch.nn.DataParallel</code>来开启多卡训练。这样每个GPU都会由一个独立的CPU核来驱动，避免了<code>DataParallel</code>的GIL问题。</p> <h2 id=none0>将梯度设置为None而不是0<a class=headerlink href=#none0 title="Permanent link">&para;</a></h2> <p>&emsp;&emsp;使用<code>.zero_grad(set_to_none=True)</code>而不是<code>.zero_grad()</code>。</p> <p>&emsp;&emsp;这会让内存分配器处理梯度，而不是主动地将他们设置为0。这只会提供一个微量的加速，就像这篇<a href=https://pytorch.org/docs/stable/optim.html>文档</a>所说的那样，所以不要期待有任何奇迹。</p> <p>&emsp;&emsp;注意这么做会有一定副作用。请仔细查看文档。</p> <h2 id=as_tensortensor>使用<code>.as_tensor</code>()而不是<code>.tensor()</code><a class=headerlink href=#as_tensortensor title="Permanent link">&para;</a></h2> <p>&emsp;&emsp;<code>torch.tensor()</code>总是会复制数据。如果你想转化一个numpy数组，使用<code>torch.as_tensor()</code>或者<code>torch.from_numpy()</code>来避免拷贝数据。</p> <h2 id=gradient-clipping>使用梯度剪裁(gradient clipping)<a class=headerlink href=#gradient-clipping title="Permanent link">&para;</a></h2> <p>&emsp;&emsp;这种方法一开始是用来避免RNN中的梯度爆炸，现在也有实验和理论说明梯度剪裁可以加速收敛。参见这篇<a href="https://openreview.net/forum?id=BJgnXpVYwS">文章</a>。</p> <p>&emsp;&emsp;抱抱脸团队实现的<a href=https://github.com/huggingface/transformers/blob/7729ef738161a0a182b172fcb7c351f6d2b9c50d/examples/run_squad.py#L156>Transformer</a>就是一个非常清晰的使用梯度裁剪的例子，这里面还用了本文提到的其他优化方法，比如AMP。</p> <p>&emsp;&emsp;现在还不清楚这种方法适用于什么样的模型，不过目前来看它在RNN架构、基于Transformer的架构，以及ResNet架构上表现出很稳定的实用性。</p> <h2 id=batchnormbias>在BatchNorm之前关掉bias<a class=headerlink href=#batchnormbias title="Permanent link">&para;</a></h2> <p>&emsp;&emsp;这非常简单：在BatchNormalization层之前关掉每一层的bias，也就是说,对于一个二维卷积层，把bias参数设为False：<code>torch.nn.Conv2d(...,bias=False,...)</code>。（原理参见这篇<a href=https://stackoverflow.com/questions/46256747/can-not-use-both-bias-and-batch-normalization-in-convolution-layers>文档</a>）</p> <h2 id=validation>在做validation的时候关掉梯度计算<a class=headerlink href=#validation title="Permanent link">&para;</a></h2> <p>&emsp;&emsp;这很简单，在validation时设置<code>torch.no_grad()</code></p> <h2 id=_5>预加载数据<a class=headerlink href=#_5 title="Permanent link">&para;</a></h2> <p>&emsp;&emsp;非常简单，用下面的DataLoaderX替换DataLoader即可：</p> <div class=highlight><pre><span></span><code><a id=__codelineno-2-1 name=__codelineno-2-1 href=#__codelineno-2-1></a>from torch.utils.data import DataLoader
<a id=__codelineno-2-2 name=__codelineno-2-2 href=#__codelineno-2-2></a>from prefetch_generator import BackgroundGenerator
<a id=__codelineno-2-3 name=__codelineno-2-3 href=#__codelineno-2-3></a>class DataLoaderX(DataLoader):
<a id=__codelineno-2-4 name=__codelineno-2-4 href=#__codelineno-2-4></a>    def __iter__(self):
<a id=__codelineno-2-5 name=__codelineno-2-5 href=#__codelineno-2-5></a>        return BackgroundGenerator(super().__iter__())
</code></pre></div> </article> </div> </div> <a href=# class="md-top md-icon" data-md-component=top data-md-state=hidden> <svg xmlns=http://www.w3.org/2000/svg viewbox="0 0 24 24"><path d="M13 20h-2V8l-5.5 5.5-1.42-1.42L12 4.16l7.92 7.92-1.42 1.42L13 8v12z"/></svg> 回到页面顶部 </a> </main> <footer class=md-footer> <nav class="md-footer__inner md-grid" aria-label=页脚> <a href=../vimtutor/ class="md-footer__link md-footer__link--prev" aria-label="上一页: VIM指令入门" rel=prev> <div class="md-footer__button md-icon"> <svg xmlns=http://www.w3.org/2000/svg viewbox="0 0 24 24"><path d="M20 11v2H8l5.5 5.5-1.42 1.42L4.16 12l7.92-7.92L13.5 5.5 8 11h12z"/></svg> </div> <div class=md-footer__title> <div class=md-ellipsis> <span class=md-footer__direction> 上一页 </span> VIM指令入门 </div> </div> </a> <a href=../tensorflow-opt/ class="md-footer__link md-footer__link--next" aria-label="下一页: TensorFlow模型优化思路" rel=next> <div class=md-footer__title> <div class=md-ellipsis> <span class=md-footer__direction> 下一页 </span> TensorFlow模型优化思路 </div> </div> <div class="md-footer__button md-icon"> <svg xmlns=http://www.w3.org/2000/svg viewbox="0 0 24 24"><path d="M4 11v2h12l-5.5 5.5 1.42 1.42L19.84 12l-7.92-7.92L10.5 5.5 16 11H4z"/></svg> </div> </a> </nav> <div class="md-footer-meta md-typeset"> <div class="md-footer-meta__inner md-grid"> <div class=md-copyright> <div class=md-copyright__highlight> Copyright &copy; 2022 CSWU-Challenge </div> Made with <a href=https://squidfunk.github.io/mkdocs-material/ target=_blank rel=noopener> Material for MkDocs </a> </div> <span id=busuanzi_container_site_pv style="color: #276747; font-size: 20px; font-weight: 600;">Total Vister:<span id=busuanzi_value_site_pv></span>Times</span> <div class=md-social> <a href=https://github.com/CSWU-Challeng/CSWU-Challenge.github.io target=_blank rel=noopener title=github.com class=md-social__link> <svg xmlns=http://www.w3.org/2000/svg viewbox="0 0 496 512"><!-- Font Awesome Free 6.0.0 by @fontawesome - https://fontawesome.com License - https://fontawesome.com/license/free (Icons: CC BY 4.0, Fonts: SIL OFL 1.1, Code: MIT License) Copyright 2022 Fonticons, Inc.--><path d="M165.9 397.4c0 2-2.3 3.6-5.2 3.6-3.3.3-5.6-1.3-5.6-3.6 0-2 2.3-3.6 5.2-3.6 3-.3 5.6 1.3 5.6 3.6zm-31.1-4.5c-.7 2 1.3 4.3 4.3 4.9 2.6 1 5.6 0 6.2-2s-1.3-4.3-4.3-5.2c-2.6-.7-5.5.3-6.2 2.3zm44.2-1.7c-2.9.7-4.9 2.6-4.6 4.9.3 2 2.9 3.3 5.9 2.6 2.9-.7 4.9-2.6 4.6-4.6-.3-1.9-3-3.2-5.9-2.9zM244.8 8C106.1 8 0 113.3 0 252c0 110.9 69.8 205.8 169.5 239.2 12.8 2.3 17.3-5.6 17.3-12.1 0-6.2-.3-40.4-.3-61.4 0 0-70 15-84.7-29.8 0 0-11.4-29.1-27.8-36.6 0 0-22.9-15.7 1.6-15.4 0 0 24.9 2 38.6 25.8 21.9 38.6 58.6 27.5 72.9 20.9 2.3-16 8.8-27.1 16-33.7-55.9-6.2-112.3-14.3-112.3-110.5 0-27.5 7.6-41.3 23.6-58.9-2.6-6.5-11.1-33.3 2.6-67.9 20.9-6.5 69 27 69 27 20-5.6 41.5-8.5 62.8-8.5s42.8 2.9 62.8 8.5c0 0 48.1-33.6 69-27 13.7 34.7 5.2 61.4 2.6 67.9 16 17.7 25.8 31.5 25.8 58.9 0 96.5-58.9 104.2-114.8 110.5 9.2 7.9 17 22.9 17 46.4 0 33.7-.3 75.4-.3 83.6 0 6.5 4.6 14.4 17.3 12.1C428.2 457.8 496 362.9 496 252 496 113.3 383.5 8 244.8 8zM97.2 352.9c-1.3 1-1 3.3.7 5.2 1.6 1.6 3.9 2.3 5.2 1 1.3-1 1-3.3-.7-5.2-1.6-1.6-3.9-2.3-5.2-1zm-10.8-8.1c-.7 1.3.3 2.9 2.3 3.9 1.6 1 3.6.7 4.3-.7.7-1.3-.3-2.9-2.3-3.9-2-.6-3.6-.3-4.3.7zm32.4 35.6c-1.6 1.3-1 4.3 1.3 6.2 2.3 2.3 5.2 2.6 6.5 1 1.3-1.3.7-4.3-1.3-6.2-2.2-2.3-5.2-2.6-6.5-1zm-11.4-14.7c-1.6 1-1.6 3.6 0 5.9 1.6 2.3 4.3 3.3 5.6 2.3 1.6-1.3 1.6-3.9 0-6.2-1.4-2.3-4-3.3-5.6-2z"/></svg> </a> </div> </div> </div> </footer> </div> <div class=md-dialog data-md-component=dialog> <div class="md-dialog__inner md-typeset"></div> </div> <script id=__config type=application/json>{"base": "../..", "features": ["content.code.annotate", "navigation.indexes", "navigation.sections", "navigation.tabs", "navigation.top", "navigation.tracking", "search.highlight", "search.share", "search.suggest", "toc.follow"], "search": "../../assets/javascripts/workers/search.d5a3c699.min.js", "translations": {"clipboard.copied": "\u5df2\u590d\u5236", "clipboard.copy": "\u590d\u5236", "search.config.lang": "ja", "search.config.pipeline": "trimmer, stemmer", "search.config.separator": "[\\uff0c\\u3002]+", "search.placeholder": "\u641c\u7d22", "search.result.more.one": "\u5728\u8be5\u9875\u4e0a\u8fd8\u6709 1 \u4e2a\u7b26\u5408\u6761\u4ef6\u7684\u7ed3\u679c", "search.result.more.other": "\u5728\u8be5\u9875\u4e0a\u8fd8\u6709 # \u4e2a\u7b26\u5408\u6761\u4ef6\u7684\u7ed3\u679c", "search.result.none": "\u6ca1\u6709\u627e\u5230\u7b26\u5408\u6761\u4ef6\u7684\u7ed3\u679c", "search.result.one": "\u627e\u5230 1 \u4e2a\u7b26\u5408\u6761\u4ef6\u7684\u7ed3\u679c", "search.result.other": "# \u4e2a\u7b26\u5408\u6761\u4ef6\u7684\u7ed3\u679c", "search.result.placeholder": "\u952e\u5165\u4ee5\u5f00\u59cb\u641c\u7d22", "search.result.term.missing": "\u7f3a\u5c11", "select.version.title": "\u9009\u62e9\u5f53\u524d\u7248\u672c"}}</script> <script src=../../assets/javascripts/bundle.897f3768.min.js></script> <script src=//busuanzi.ibruce.info/busuanzi/2.3/busuanzi.pure.mini.js></script> <script src=https://cdn.jsdelivr.net/npm/mathjax@3/es5/tex-mml-chtml.js></script> <script src=../../overrides/assets/javascripts/bundle.a375bc7d.min.js></script> </body> </html>